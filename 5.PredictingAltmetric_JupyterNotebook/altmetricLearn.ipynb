{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18492b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = '/work/teghipco/LLMs/Biobert/pubs_all.parquet'\n",
    "df = pd.read_parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b789f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2979275, 30)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de584c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   publication_id  year        date date_online  \\\n",
      "0  pub.1142700518  2021  2021-11-19  2021-11-19   \n",
      "1  pub.1157734354  2023  2023-05-04  2023-05-04   \n",
      "2  pub.1176144398  2024  2024-09-30  2024-09-30   \n",
      "3  pub.1133314038  2020  2020-11-01        None   \n",
      "4  pub.1168937635  2024  2024-02-06        None   \n",
      "\n",
      "                                     title_preferred clinical_trial_ids  \\\n",
      "0  P11â€17: Outcomes of COVID 19 critical care pat...                      \n",
      "1  The Bronte Creek Project: Outdoor Environmenta...                      \n",
      "2  (Mis)recognising the symbolic violence of acad...                      \n",
      "3                                  Lunar dust buster                      \n",
      "4               Lessons from COVID-19: UK experience                      \n",
      "\n",
      "  times_cited recent_citations publication_type  is_open_access  ...  \\\n",
      "0           0                0          article            True  ...   \n",
      "1           0                0          chapter            True  ...   \n",
      "2           0                0          article            True  ...   \n",
      "3           0                0          article            True  ...   \n",
      "4           0                0          chapter            True  ...   \n",
      "\n",
      "  field_citation_ratio field proceedings_title_preferred conference_name  \\\n",
      "0                  NaN  None                        None            None   \n",
      "1                  NaN  None                        None            None   \n",
      "2                  NaN  None                        None            None   \n",
      "3                  0.0  None                        None            None   \n",
      "4                  NaN  None                        None            None   \n",
      "\n",
      "  citation_count title_original relative_citation_ratio dataset_count  \\\n",
      "0            NaN           None                     NaN             1   \n",
      "1            NaN           None                     NaN             1   \n",
      "2            NaN           None                     NaN             1   \n",
      "3            NaN           None                     NaN             1   \n",
      "4            NaN           None                     NaN             1   \n",
      "\n",
      "  grant_count  patent_count  \n",
      "0           0             0  \n",
      "1           0             0  \n",
      "2           0             0  \n",
      "3           0             0  \n",
      "4           0             0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f327fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['title_preferred', 'proceedings_title_preferred', 'conference_name', 'title_original']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48764f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   publication_id  year        date date_online clinical_trial_ids  \\\n",
      "0  pub.1142700518  2021  2021-11-19  2021-11-19                      \n",
      "1  pub.1157734354  2023  2023-05-04  2023-05-04                      \n",
      "2  pub.1176144398  2024  2024-09-30  2024-09-30                      \n",
      "3  pub.1133314038  2020  2020-11-01        None                      \n",
      "4  pub.1168937635  2024  2024-02-06        None                      \n",
      "\n",
      "  times_cited recent_citations publication_type  is_open_access  \\\n",
      "0           0                0          article            True   \n",
      "1           0                0          chapter            True   \n",
      "2           0                0          article            True   \n",
      "3           0                0          article            True   \n",
      "4           0                0          chapter            True   \n",
      "\n",
      "                                             authors  ...  \\\n",
      "0  [{'author_grid_ids': [], 'first_name': None, '...  ...   \n",
      "1  [{'author_grid_ids': [], 'first_name': 'John',...  ...   \n",
      "2  [{'author_grid_ids': [], 'first_name': 'France...  ...   \n",
      "3  [{'author_grid_ids': [], 'first_name': None, '...  ...   \n",
      "4  [{'author_grid_ids': [], 'first_name': 'Malcol...  ...   \n",
      "\n",
      "                                  abstract_preferred  \\\n",
      "0                                               None   \n",
      "1  The Bronte Creek Project (BCP) was a unique en...   \n",
      "2  This paper contributes to critical scholarship...   \n",
      "3  Any astronauts thinking of living on the Moon ...   \n",
      "4                                               None   \n",
      "\n",
      "                                book_title_preferred altmetric_score  \\\n",
      "0                                               None             NaN   \n",
      "1  Outdoor Environmental Education in the Contemp...             NaN   \n",
      "2                                               None             8.0   \n",
      "3                                               None             NaN   \n",
      "4                           Post Keynesian Economics             NaN   \n",
      "\n",
      "  field_citation_ratio field citation_count relative_citation_ratio  \\\n",
      "0                  NaN  None            NaN                     NaN   \n",
      "1                  NaN  None            NaN                     NaN   \n",
      "2                  NaN  None            NaN                     NaN   \n",
      "3                  0.0  None            NaN                     NaN   \n",
      "4                  NaN  None            NaN                     NaN   \n",
      "\n",
      "  dataset_count  grant_count  patent_count  \n",
      "0             1            0             0  \n",
      "1             1            0             0  \n",
      "2             1            0             0  \n",
      "3             1            0             0  \n",
      "4             1            0             0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47086e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['abstract_preferred']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0e64d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['book_title_preferred']\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a970c6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   publication_id  year        date date_online clinical_trial_ids  \\\n",
      "0  pub.1142700518  2021  2021-11-19  2021-11-19                      \n",
      "1  pub.1157734354  2023  2023-05-04  2023-05-04                      \n",
      "2  pub.1176144398  2024  2024-09-30  2024-09-30                      \n",
      "3  pub.1133314038  2020  2020-11-01        None                      \n",
      "4  pub.1168937635  2024  2024-02-06        None                      \n",
      "\n",
      "  times_cited recent_citations publication_type  is_open_access  \\\n",
      "0           0                0          article            True   \n",
      "1           0                0          chapter            True   \n",
      "2           0                0          article            True   \n",
      "3           0                0          article            True   \n",
      "4           0                0          chapter            True   \n",
      "\n",
      "                                             authors  ...  \\\n",
      "0  [{'author_grid_ids': [], 'first_name': None, '...  ...   \n",
      "1  [{'author_grid_ids': [], 'first_name': 'John',...  ...   \n",
      "2  [{'author_grid_ids': [], 'first_name': 'France...  ...   \n",
      "3  [{'author_grid_ids': [], 'first_name': None, '...  ...   \n",
      "4  [{'author_grid_ids': [], 'first_name': 'Malcol...  ...   \n",
      "\n",
      "  research_org_state_codes num_unique_orgs altmetric_score  \\\n",
      "0                                        0             NaN   \n",
      "1                    CA-ON               0             NaN   \n",
      "2                                        0             8.0   \n",
      "3                                        0             NaN   \n",
      "4                                        0             NaN   \n",
      "\n",
      "  field_citation_ratio field citation_count  relative_citation_ratio  \\\n",
      "0                  NaN  None            NaN                      NaN   \n",
      "1                  NaN  None            NaN                      NaN   \n",
      "2                  NaN  None            NaN                      NaN   \n",
      "3                  0.0  None            NaN                      NaN   \n",
      "4                  NaN  None            NaN                      NaN   \n",
      "\n",
      "   dataset_count grant_count  patent_count  \n",
      "0              1           0             0  \n",
      "1              1           0             0  \n",
      "2              1           0             0  \n",
      "3              1           0             0  \n",
      "4              1           0             0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f0bd668",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 193. GiB for an array with shape (2979275, 69410) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresearch_org_state_codes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresearch_org_state_codes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# One-hot encode research_org_state_codes\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresearch_org_state_codes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cpuLLM/lib/python3.10/site-packages/pandas/core/reshape/encoding.py:214\u001b[0m, in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    210\u001b[0m     with_dummies \u001b[38;5;241m=\u001b[39m [data\u001b[38;5;241m.\u001b[39mselect_dtypes(exclude\u001b[38;5;241m=\u001b[39mdtypes_to_encode)]\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, pre, sep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_to_encode\u001b[38;5;241m.\u001b[39mitems(), prefix, prefix_sep):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# col is (column_name, column), use just column data here\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m     dummy \u001b[38;5;241m=\u001b[39m \u001b[43m_get_dummies_1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix_sep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdummy_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdummy_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m     with_dummies\u001b[38;5;241m.\u001b[39mappend(dummy)\n\u001b[1;32m    224\u001b[0m result \u001b[38;5;241m=\u001b[39m concat(with_dummies, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/cpuLLM/lib/python3.10/site-packages/pandas/core/reshape/encoding.py:353\u001b[0m, in \u001b[0;36m_get_dummies_1d\u001b[0;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     dummy_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_\n\u001b[0;32m--> 353\u001b[0m dummy_mat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdummy_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m dummy_mat[np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(codes)), codes] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dummy_na:\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# reset NaN GH4446\u001b[39;00m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 193. GiB for an array with shape (2979275, 69410) and data type bool"
     ]
    }
   ],
   "source": [
    "df['num_authors'] = df['authors'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "df['is_open_access'] = df['is_open_access'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2f64bc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['publication_type'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# One-hot encode publication_type\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpublication_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cpuLLM/lib/python3.10/site-packages/pandas/core/reshape/encoding.py:169\u001b[0m, in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a list-like for parameter `columns`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     data_to_encode \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_len\u001b[39m(item, name: \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/cpuLLM/lib/python3.10/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/cpuLLM/lib/python3.10/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cpuLLM/lib/python3.10/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['publication_type'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# One-hot encode publication_type\n",
    "df = pd.get_dummies(df, columns=['publication_type'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff5b9cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['publication_id', 'year', 'clinical_trial_ids', 'times_cited',\n",
      "       'recent_citations', 'is_open_access', 'authors', 'funding_details',\n",
      "       'unique_org_ids', 'research_org_city_ids', 'research_org_country_codes',\n",
      "       'research_org_state_codes', 'num_unique_orgs', 'altmetric_score',\n",
      "       'field_citation_ratio', 'field', 'citation_count',\n",
      "       'relative_citation_ratio', 'dataset_count', 'grant_count',\n",
      "       'patent_count', 'num_authors', 'publication_type_book',\n",
      "       'publication_type_chapter', 'publication_type_monograph',\n",
      "       'publication_type_preprint', 'publication_type_proceeding',\n",
      "       'publication_type_seminar', 'date_diff_days'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2ae2fa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/cpuLLM/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_online\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_online\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/cpuLLM/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.conda/envs/cpuLLM/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df['date_online'] = pd.to_datetime(df['date_online'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8458e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['altmetric_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9489f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values for numeric columns with 0 or the median, depending on context\n",
    "df['field_citation_ratio'] = df['field_citation_ratio'].fillna(0)\n",
    "df['citation_count'] = df['citation_count'].fillna(0)\n",
    "df['relative_citation_ratio'] = df['relative_citation_ratio'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2968fa7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 193. GiB for an array with shape (2979275, 69410) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresearch_org_state_codes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresearch_org_state_codes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# One-hot encode research_org_state_codes\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresearch_org_state_codes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cpuLLM/lib/python3.10/site-packages/pandas/core/reshape/encoding.py:214\u001b[0m, in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    210\u001b[0m     with_dummies \u001b[38;5;241m=\u001b[39m [data\u001b[38;5;241m.\u001b[39mselect_dtypes(exclude\u001b[38;5;241m=\u001b[39mdtypes_to_encode)]\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, pre, sep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_to_encode\u001b[38;5;241m.\u001b[39mitems(), prefix, prefix_sep):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# col is (column_name, column), use just column data here\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m     dummy \u001b[38;5;241m=\u001b[39m \u001b[43m_get_dummies_1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix_sep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdummy_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdummy_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m     with_dummies\u001b[38;5;241m.\u001b[39mappend(dummy)\n\u001b[1;32m    224\u001b[0m result \u001b[38;5;241m=\u001b[39m concat(with_dummies, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/cpuLLM/lib/python3.10/site-packages/pandas/core/reshape/encoding.py:353\u001b[0m, in \u001b[0;36m_get_dummies_1d\u001b[0;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     dummy_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_\n\u001b[0;32m--> 353\u001b[0m dummy_mat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdummy_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m dummy_mat[np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(codes)), codes] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dummy_na:\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# reset NaN GH4446\u001b[39;00m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 193. GiB for an array with shape (2979275, 69410) and data type bool"
     ]
    }
   ],
   "source": [
    "# Fill categorical columns with a placeholder if necessary\n",
    "df['research_org_state_codes'] = df['research_org_state_codes'].fillna('Unknown')\n",
    "# One-hot encode research_org_state_codes\n",
    "df = pd.get_dummies(df, columns=['research_org_state_codes'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ed45563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['publication_id', 'year', 'clinical_trial_ids', 'times_cited',\n",
      "       'recent_citations', 'is_open_access', 'authors', 'funding_details',\n",
      "       'unique_org_ids', 'research_org_city_ids', 'research_org_country_codes',\n",
      "       'research_org_state_codes', 'num_unique_orgs', 'altmetric_score',\n",
      "       'field_citation_ratio', 'field', 'citation_count',\n",
      "       'relative_citation_ratio', 'dataset_count', 'grant_count',\n",
      "       'patent_count', 'num_authors', 'publication_type_book',\n",
      "       'publication_type_chapter', 'publication_type_monograph',\n",
      "       'publication_type_preprint', 'publication_type_proceeding',\n",
      "       'publication_type_seminar', 'date_diff_days'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7611403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of clinical trial IDs by splitting the string\n",
    "df['num_clinical_trial_ids'] = df['clinical_trial_ids'].apply(lambda x: len(x.split(',')) if pd.notnull(x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c911927f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   4   6   8  16  11  22  68   3  84   7  13  27  21  20  61   5\n",
      "  34  15   9  55  29  63  72  25  87  73  17  23  10  18  56  19  53  58\n",
      "  35  33  12  36  32  24  49  14  71  44  52 104  43  48 137  40 127  38\n",
      "  79  74  67  26  80  28  83  45  31  30 118  57  39  54  82  66 214  93\n",
      "  91 112  86  37  46 124  88 122  42  96  92 154  70 217  41  95 119  51\n",
      "  59  60  81  47  85  76  75 115 108 142  62 116 173 125  78 106  89  77\n",
      " 121 232 117 178 248 231 401  50 212  65  64 188 149 169 183 139 235  69\n",
      " 126 384 145 101 207  97 210 103 204 194 350 165  90 174 159 120 135 211\n",
      " 284 143 146 113 134 412 195 260 153  99 409 203 177 185  98 128 357 107\n",
      " 111 102 167 270 161 155 151 486 247 171 105 763 114 236 160 168 147 110\n",
      " 304 109 184 176 377 249 315 162 131 123 130 234 498 221 313 179 295 133\n",
      " 136  94 261 216 201 156 140 144 287 291 190 189 506 293 253 100 157 209\n",
      " 297 186 175 198 181 250 299 391 152 282 289 292 200 180 138 129]\n"
     ]
    }
   ],
   "source": [
    "print(df['num_clinical_trial_ids'].unique())    # Displays unique values, including any non-zero counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "440c93e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_unique_city_ids'] = df['research_org_city_ids'].apply(lambda x: len(set(x.split(','))) if pd.notnull(x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "858d7832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_unique_country_codes'] = df['research_org_country_codes'].apply(lambda x: len(set(x.split(','))) if pd.notnull(x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "868c150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_unique_state_codes'] = df['research_org_state_codes'].apply(lambda x: len(set(x.split(','))) if pd.notnull(x) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ebfc339",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['clinical_trial_ids','field','research_org_state_codes','funding_details','unique_org_ids','research_org_city_ids','research_org_country_codes','research_org_state_codes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5dfefcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          1\n",
      "1          1\n",
      "2          1\n",
      "3          1\n",
      "4          1\n",
      "          ..\n",
      "2979270    1\n",
      "2979271    2\n",
      "2979272    1\n",
      "2979273    1\n",
      "2979274    1\n",
      "Name: num_unique_country_codes, Length: 2979275, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.num_unique_country_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2effd20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['publication_id', 'year', 'times_cited', 'recent_citations',\n",
      "       'is_open_access', 'authors', 'num_unique_orgs', 'altmetric_score',\n",
      "       'field_citation_ratio', 'citation_count', 'relative_citation_ratio',\n",
      "       'dataset_count', 'grant_count', 'patent_count', 'num_authors',\n",
      "       'publication_type_book', 'publication_type_chapter',\n",
      "       'publication_type_monograph', 'publication_type_preprint',\n",
      "       'publication_type_proceeding', 'publication_type_seminar',\n",
      "       'date_diff_days', 'num_clinical_trial_ids', 'num_unique_city_ids',\n",
      "       'num_unique_country_codes', 'num_unique_state_codes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfa7df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = df.drop(columns=['altmetric_score'])  # Drop target column from features\n",
    "y = df['altmetric_score']  # Define target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "834603d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2979275, 25)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bb34c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out pub_id and authors into their own variables for future reference\n",
    "pub_id = df['publication_id']\n",
    "authors_info = df['authors']\n",
    "\n",
    "# Drop 'publication_id' and 'authors' from the feature set\n",
    "X = df.drop(columns=['publication_id', 'authors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e97d7a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_parquet(\"X_features.parquet\")\n",
    "y.to_frame(name='altmetric_score').to_parquet(\"y_target.parquet\")  # Convert y to a DataFrame first\n",
    "pub_id.to_frame(name='pub_id').to_parquet(\"pub_id.parquet\")\n",
    "authors_info.to_frame(name='authors_info').to_parquet(\"authors_info.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46e40f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables you want to keep\n",
    "keep_vars = ['X', 'y', 'pub_id', 'authors_info']\n",
    "\n",
    "# Delete all other variables except those in keep_vars\n",
    "for var in list(globals().keys()):\n",
    "    if var not in keep_vars and not var.startswith(\"__\"):\n",
    "        del globals()[var]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d03797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "from sklearn.model_selection import GroupKFold, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f5326ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types in X_train after explicit conversion:\n",
      " year                             int64\n",
      "times_cited                    float64\n",
      "recent_citations               float64\n",
      "is_open_access                   int64\n",
      "num_unique_orgs                  int64\n",
      "altmetric_score                float64\n",
      "field_citation_ratio           float64\n",
      "citation_count                 float64\n",
      "relative_citation_ratio        float64\n",
      "dataset_count                    int64\n",
      "grant_count                      int64\n",
      "patent_count                     int64\n",
      "num_authors                      int64\n",
      "publication_type_book             bool\n",
      "publication_type_chapter          bool\n",
      "publication_type_monograph        bool\n",
      "publication_type_preprint         bool\n",
      "publication_type_proceeding       bool\n",
      "publication_type_seminar          bool\n",
      "date_diff_days                 float64\n",
      "num_clinical_trial_ids           int64\n",
      "num_unique_city_ids              int64\n",
      "num_unique_country_codes         int64\n",
      "num_unique_state_codes           int64\n",
      "dtype: object\n",
      "Data types in X_test after explicit conversion:\n",
      " year                             int64\n",
      "times_cited                    float64\n",
      "recent_citations               float64\n",
      "is_open_access                   int64\n",
      "num_unique_orgs                  int64\n",
      "altmetric_score                float64\n",
      "field_citation_ratio           float64\n",
      "citation_count                 float64\n",
      "relative_citation_ratio        float64\n",
      "dataset_count                    int64\n",
      "grant_count                      int64\n",
      "patent_count                     int64\n",
      "num_authors                      int64\n",
      "publication_type_book             bool\n",
      "publication_type_chapter          bool\n",
      "publication_type_monograph        bool\n",
      "publication_type_preprint         bool\n",
      "publication_type_proceeding       bool\n",
      "publication_type_seminar          bool\n",
      "date_diff_days                 float64\n",
      "num_clinical_trial_ids           int64\n",
      "num_unique_city_ids              int64\n",
      "num_unique_country_codes         int64\n",
      "num_unique_state_codes           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Explicitly use .loc to assign values to avoid the SettingWithCopyWarning\n",
    "for col in ['year', 'times_cited', 'recent_citations', 'num_unique_orgs']:\n",
    "    X_train.loc[:, col] = pd.to_numeric(X_train[col], errors='coerce')\n",
    "    X_test.loc[:, col] = pd.to_numeric(X_test[col], errors='coerce')\n",
    "\n",
    "# Verify final data types\n",
    "print(\"Data types in X_train after explicit conversion:\\n\", X_train.dtypes)\n",
    "print(\"Data types in X_test after explicit conversion:\\n\", X_test.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d3a2150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a unique identifier for each author\n",
    "def get_author_id(author):\n",
    "    if len(author['author_grid_ids']) > 0:  # Check if 'author_grid_ids' is not empty\n",
    "        return author['author_grid_ids'][0]  # Use the first ID in the list\n",
    "    else:  # Fallback on 'first_name' and 'last_name'\n",
    "        return f\"{author.get('first_name', '')}_{author.get('last_name', '')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b46b508c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             [None_None]\n",
      "1         [John_McKillop]\n",
      "2    [Francesca_MCCARTHY]\n",
      "3             [None_None]\n",
      "4        [Malcolm_Sawyer]\n",
      "Name: authors, dtype: object\n"
     ]
    }
   ],
   "source": [
    "authors_ids = authors_info.apply(lambda authors: [get_author_id(author) for author in authors])\n",
    "print(authors_ids.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ae2b99c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             [None_None]\n",
      "1         [John_McKillop]\n",
      "2    [Francesca_MCCARTHY]\n",
      "3             [None_None]\n",
      "4        [Malcolm_Sawyer]\n",
      "Name: authors, dtype: object\n"
     ]
    }
   ],
   "source": [
    "authors_ids = authors_info.apply(lambda authors: [get_author_id(author) for author in authors])\n",
    "print(authors_ids.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4362c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine authors per publication to create a single identifier\n",
    "authors_groups = authors_ids.apply(lambda ids: \"_\".join(map(str, ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf1dc90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify there are no NaNs in groups\n",
    "authors_groups = authors_groups.fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c8d7a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deep copies to avoid SettingWithCopyWarning\n",
    "X_clean = X.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "de32dcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting unique types in X_clean:\n",
      "\n",
      "Column: 'year' has the following unique types:\n",
      " - <class 'str'>\n",
      "\n",
      "Column: 'times_cited' has the following unique types:\n",
      " - <class 'str'>\n",
      " - <class 'NoneType'>\n",
      "\n",
      "Column: 'recent_citations' has the following unique types:\n",
      " - <class 'str'>\n",
      " - <class 'NoneType'>\n",
      "\n",
      "Column: 'num_unique_orgs' has the following unique types:\n",
      " - <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# List of problematic columns\n",
    "problematic_cols = ['year', 'times_cited', 'recent_citations', 'num_unique_orgs']\n",
    "\n",
    "# Function to display unique types\n",
    "def display_unique_types(df, cols):\n",
    "    for col in cols:\n",
    "        unique_types = df[col].apply(type).unique()\n",
    "        print(f\"\\nColumn: '{col}' has the following unique types:\")\n",
    "        for ut in unique_types:\n",
    "            print(f\" - {ut}\")\n",
    "\n",
    "# Inspect unique types in X_clean\n",
    "print(\"Inspecting unique types in X_clean:\")\n",
    "display_unique_types(X_clean, problematic_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4a9efeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 entries in 'year' of X_train_clean:\n",
      "1     2023.0\n",
      "2     2024.0\n",
      "4     2024.0\n",
      "5     2023.0\n",
      "8     2024.0\n",
      "9     2023.0\n",
      "12    2023.0\n",
      "14    2024.0\n",
      "17    2023.0\n",
      "18    2020.0\n",
      "Name: year, dtype: object\n",
      "\n",
      "First 10 entries in 'times_cited' of X_train_clean:\n",
      "1     0.0\n",
      "2     0.0\n",
      "4     0.0\n",
      "5     0.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "12    0.0\n",
      "14    0.0\n",
      "17    0.0\n",
      "18    0.0\n",
      "Name: times_cited, dtype: object\n",
      "\n",
      "First 10 entries in 'recent_citations' of X_train_clean:\n",
      "1     0.0\n",
      "2     0.0\n",
      "4     0.0\n",
      "5     0.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "12    0.0\n",
      "14    0.0\n",
      "17    0.0\n",
      "18    0.0\n",
      "Name: recent_citations, dtype: object\n",
      "\n",
      "First 10 entries in 'num_unique_orgs' of X_train_clean:\n",
      "1     0.0\n",
      "2     0.0\n",
      "4     0.0\n",
      "5     0.0\n",
      "8     0.0\n",
      "9     0.0\n",
      "12    0.0\n",
      "14    0.0\n",
      "17    0.0\n",
      "18    0.0\n",
      "Name: num_unique_orgs, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display first few entries of problematic columns in X_train_clean\n",
    "for col in problematic_cols:\n",
    "    print(f\"\\nFirst 10 entries in '{col}' of X_train_clean:\")\n",
    "    print(X_train_clean[col].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0e0712c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted 'year' to float.\n",
      "Successfully converted 'times_cited' to float.\n",
      "Successfully converted 'recent_citations' to float.\n",
      "Successfully converted 'num_unique_orgs' to float.\n"
     ]
    }
   ],
   "source": [
    "# Convert problematic columns to numeric types using .astype()\n",
    "for col in problematic_cols:\n",
    "    try:\n",
    "        X_clean[col] = X_clean[col].astype(float)\n",
    "        print(f\"Successfully converted '{col}' to float.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting '{col}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ef28e671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost model fitted successfully without Bayesian optimization.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define the XGBoost model\n",
    "model = XGBRegressor(missing=np.nan, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "try:\n",
    "    model.fit(X_clean, y)\n",
    "    print(\"\\nXGBoost model fitted successfully without Bayesian optimization.\")\n",
    "except Exception as e:\n",
    "    print(\"\\nError during XGBoost model fitting:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a7ab7131",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(missing=np.nan, n_jobs=-1, enable_categorical=True)\n",
    "# Define parameter search space for Bayesian optimization\n",
    "from skopt.space import Integer, Real\n",
    "param_space = {\n",
    "    'n_estimators': Integer(50, 5000),\n",
    "    'max_depth': Integer(3, 15),\n",
    "    'learning_rate': Real(0.01, 0.2, 'log-uniform'),\n",
    "    'subsample': Real(0.5, 1.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3b150b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = TimeSeriesSplit(n_splits=4)\n",
    "inner_cv = TimeSeriesSplit(n_splits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "69aee00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from fold 5\n",
      "Checkpoint loaded - Start fold: 4, RMSE scores: [np.float64(109.86921728414308), np.float64(63.47812610292604), np.float64(68.14318936758099), np.float64(49.87415927697745)], MAE scores: [np.float64(3.188687765043222), np.float64(2.155909136049051), np.float64(1.3475056230235132), np.float64(1.8557800355756917)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pickle\n",
    "\n",
    "# Set to True to resume from checkpoint, False to start fresh\n",
    "resume_from_checkpoint = True\n",
    "\n",
    "# Filepaths for checkpoint files\n",
    "results_file = \"/work/teghipco/LLMs/Biobert/bayesian_optimization_results_checkpoint_altmetric.csv\"\n",
    "predictions_file = \"/work/teghipco/LLMs/Biobert/bayesian_optimization_predictions_checkpoint_altmetric.csv\"\n",
    "state_file = \"/work/teghipco/LLMs/Biobert/bayesian_optimization_state_altmetric.pkl\"\n",
    "\n",
    "# Initialize lists to store RMSE, MAE, and predictions for each outer fold\n",
    "outer_rmse_scores = []\n",
    "outer_mae_scores = []\n",
    "all_predictions = []\n",
    "\n",
    "# Resume or start fresh based on the switch\n",
    "if resume_from_checkpoint and os.path.exists(state_file):\n",
    "    # Load previous state if checkpoint exists and resuming\n",
    "    with open(state_file, \"rb\") as f:\n",
    "        checkpoint_data = pickle.load(f)\n",
    "        start_fold = checkpoint_data['start_fold']\n",
    "        outer_rmse_scores = checkpoint_data['outer_rmse_scores']\n",
    "        outer_mae_scores = checkpoint_data['outer_mae_scores']\n",
    "        results_df = pd.read_csv(results_file)\n",
    "        all_predictions_df = pd.read_csv(predictions_file)\n",
    "        all_predictions = [all_predictions_df]  # initialize with existing predictions\n",
    "    print(f\"Resuming from fold {start_fold + 1}\")\n",
    "    print(f\"Checkpoint loaded - Start fold: {start_fold}, RMSE scores: {outer_rmse_scores}, MAE scores: {outer_mae_scores}\")\n",
    "else:\n",
    "    # Start fresh, initialize from scratch\n",
    "    start_fold = 0\n",
    "    results_df = pd.DataFrame(columns=[\"Outer Fold\", \"RMSE\", \"MAE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a338b229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All folds completed. Checkpoint files cleaned up if starting fresh.\n"
     ]
    }
   ],
   "source": [
    "# Outer loop: Train on consecutive years, test on future years\n",
    "for outer_fold, (train_index, test_index) in enumerate(outer_cv.split(X_clean)):\n",
    "    if outer_fold < start_fold:\n",
    "        continue  # Skip completed folds\n",
    "\n",
    "    # Identify unique authors in the test set\n",
    "    test_authors = set(authors_groups.iloc[test_index])\n",
    "\n",
    "    # Filter training set to exclude any authors that appear in the test set\n",
    "    filtered_train_index = [i for i in train_index if authors_groups.iloc[i] not in test_authors]\n",
    "    \n",
    "    # Prepare training and test sets\n",
    "    X_train_clean, X_test_clean = X_clean.iloc[filtered_train_index], X_clean.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[filtered_train_index], y.iloc[test_index]\n",
    "    filtered_train_authors = authors_groups.iloc[filtered_train_index]\n",
    "    \n",
    "    # Scale X and y\n",
    "    X_scaler = StandardScaler()\n",
    "    y_scaler = StandardScaler()\n",
    "\n",
    "    X_train_scaled = X_scaler.fit_transform(X_train_clean)\n",
    "    X_test_scaled = X_scaler.transform(X_test_clean)\n",
    "    y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "    y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Set up inner GroupKFold cross-validation using the filtered author groups\n",
    "    inner_cv = GroupKFold(n_splits=3)\n",
    "\n",
    "    # Define Bayesian optimization\n",
    "    opt = BayesSearchCV(\n",
    "        model,\n",
    "        param_space,\n",
    "        cv=inner_cv.split(X_train_scaled, y_train_scaled, groups=filtered_train_authors),\n",
    "        n_iter=80,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=3,\n",
    "    )\n",
    "\n",
    "    # Fit the Bayesian optimization\n",
    "    print(f\"Starting Bayesian optimization for outer fold {outer_fold + 1}\")\n",
    "    opt.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "    # Evaluate on the outer test set\n",
    "    y_pred_scaled = opt.predict(X_test_scaled)\n",
    "    y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "    y_test_orig = y_scaler.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Calculate RMSE and MAE\n",
    "    rmse = np.sqrt(np.mean((y_pred - y_test_orig) ** 2))\n",
    "    mae = mean_absolute_error(y_test_orig, y_pred)\n",
    "    \n",
    "    # Save results for this fold\n",
    "    outer_rmse_scores.append(rmse)\n",
    "    outer_mae_scores.append(mae)\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([{\"Outer Fold\": outer_fold + 1, \"RMSE\": rmse, \"MAE\": mae}])], ignore_index=True)\n",
    "\n",
    "    # Save predictions\n",
    "    fold_predictions = pd.DataFrame({\n",
    "        \"Outer Fold\": outer_fold + 1,\n",
    "        \"Publication ID\": pub_id.iloc[test_index],\n",
    "        \"Actual Altmetric Score\": y_test_orig,\n",
    "        \"Predicted Altmetric Score\": y_pred\n",
    "    })\n",
    "    all_predictions.append(fold_predictions)\n",
    "\n",
    "    # Save checkpoints after each fold\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    all_predictions_df = pd.concat(all_predictions, ignore_index=True)\n",
    "    all_predictions_df.to_csv(predictions_file, index=False)\n",
    "\n",
    "    # Update the checkpoint data\n",
    "    checkpoint_data = {\n",
    "        'start_fold': outer_fold + 1,\n",
    "        'outer_rmse_scores': outer_rmse_scores,\n",
    "        'outer_mae_scores': outer_mae_scores,\n",
    "    }\n",
    "    with open(state_file, \"wb\") as f:\n",
    "        pickle.dump(checkpoint_data, f)\n",
    "\n",
    "    print(f\"Outer fold {outer_fold + 1} completed - RMSE: {rmse}, MAE: {mae}\")\n",
    "\n",
    "# After all folds are done, clean up checkpoint files if starting fresh\n",
    "if not resume_from_checkpoint:\n",
    "    for file in [state_file, results_file, predictions_file]:\n",
    "        if os.path.exists(file):\n",
    "            os.remove(file)\n",
    "\n",
    "print(\"All folds completed. Checkpoint files cleaned up if starting fresh.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8590677a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Pearson correlation between actual and predicted Altmetric scores: 0.901786741971732\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Concatenate all actual and predicted values across all folds\n",
    "all_actual_values = pd.concat([fold[\"Actual Altmetric Score\"] for fold in all_predictions], ignore_index=True)\n",
    "all_predicted_values = pd.concat([fold[\"Predicted Altmetric Score\"] for fold in all_predictions], ignore_index=True)\n",
    "\n",
    "# Calculate the overall Pearson correlation coefficient\n",
    "correlation, _ = pearsonr(all_actual_values, all_predicted_values)\n",
    "\n",
    "# Print the correlation\n",
    "print(f\"\\nOverall Pearson correlation between actual and predicted Altmetric scores: {correlation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d2152984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2383420,)\n"
     ]
    }
   ],
   "source": [
    "print(all_actual_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "64bb2953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2979275,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b81bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
